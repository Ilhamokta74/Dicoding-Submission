# -*- coding: utf-8 -*-
"""Sub_1_Model_NLP_dengan_TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14T3gbxkhbG6aQNdI7bZZJhst-o6CNcc1

*   Nama : Ilham Oktavian
*   Dataset : train.csv
*   Sumber : Kaggle
*   Link Dataset : https://www.kaggle.com/lokkagle/movie-genre-data
"""

from google.colab import drive
drive.mount('/content/drive')

# Library
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import matplotlib.pyplot as plt
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout
from tensorflow.keras.models import Sequential

# Membaca data dari file CSV
file_path = './drive/MyDrive/Dataset/sub 1/train.csv'
data = pd.read_csv(file_path, sep=',')

# Menampilkan beberapa baris terakhir dari data
tail_data = data.tail()
tail_data

# Menghitung dan menampilkan jumlah nilai unik dalam kolom 'genre'
genre_counts = data['genre'].value_counts()
genre_counts

# Menghapus kolom 'id' dari DataFrame
data = data.drop(columns=['id'])
data.head()

# Memfilter data dengan menghilangkan beberapa nilai dalam kolom 'genre'
genres_to_exclude = ['sci-fi', 'horror', 'other', 'adventure', 'romance']
filtered_data = data[~data['genre'].isin(genres_to_exclude)]

# Menampilkan jumlah nilai unik dalam kolom 'genre' setelah penghapusan
filtered_genre_counts = filtered_data['genre'].value_counts()
filtered_genre_counts

# Membuat kolom-kolom dummy untuk nilai unik dalam kolom 'genre'
genre_dummies = pd.get_dummies(filtered_data['genre'])

# Menggabungkan DataFrame asli dengan kolom-kolom dummy
data_baru = pd.concat([filtered_data, genre_dummies], axis=1)

# Menghapus kolom 'genre' asli setelah membuat kolom-kolom dummy
data_baru = data_baru.drop(columns='genre')

# Menampilkan DataFrame yang telah dimodifikasi
data_baru

data_baru.columns

# Mengambil kolom 'text' dan mengonversi ke tipe data string
tentang_film = data_baru['text'].astype(str)

# Mengambil kolom 'action', 'comedy', 'drama', dan 'thriller' sebagai nilai genre_film
genre_film = data_baru[['action', 'comedy', 'drama', 'thriller']].values

# Memisahkan data menjadi set latih dan set uji
tentang_latih, tentang_test, genre_latih, genre_test = train_test_split(
    tentang_film,  # Kolom 'text' atau 'about' (sesuai dengan data Anda)
    genre_film,
    test_size=0.2
)

# Inisialisasi Tokenizer dengan jumlah kata maksimum 5000 dan token untuk out-of-vocabulary
tokenizer = Tokenizer(num_words=5000, oov_token='*')

# Fitting Tokenizer pada data latih dan data uji
tokenizer.fit_on_texts(tentang_latih)
tokenizer.fit_on_texts(tentang_test)

# Mengonversi teks ke dalam urutan angka (sequences)
sekuens_latih = tokenizer.texts_to_sequences(tentang_latih)
sekuens_test = tokenizer.texts_to_sequences(tentang_test)

# Melakukan padding pada urutan angka agar memiliki panjang yang sama
padded_latih = pad_sequences(sekuens_latih)
padded_test = pad_sequences(sekuens_test)

# Model Sequential
model = Sequential([
    Embedding(input_dim=5000, output_dim=16),
    LSTM(64),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')
])

# Pengaturan optimizer Adam dengan learning rate 0.00146
optimizer = Adam(learning_rate=0.00146)

# Menggunakan optimizer yang telah diatur dalam model.compile
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

class ModelCallbacks(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if logs.get('val_accuracy') is not None and logs.get('val_accuracy') > 0.9:
            print("Expected accuracy has been achieved. Stopping training.")
            self.model.stop_training = True

# Membuat objek callback
cb = ModelCallbacks()

model_history = model.fit(
    padded_latih,
    genre_latih,
    epochs=50,
    validation_data=(padded_test, genre_test),
    verbose=2,
    batch_size=128,
    callbacks=[cb]
)

# Plot loss untuk pelatihan dan validasi
plt.plot(model_history.history['loss'], label='Train Loss')
plt.plot(model_history.history['val_loss'], label='Validation Loss')

# Menambahkan judul, label sumbu, dan legenda
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')

# Menampilkan plot
plt.show()

# Plot akurasi untuk pelatihan dan validasi
plt.plot(model_history.history['accuracy'], label='Train Accuracy')
plt.plot(model_history.history['val_accuracy'], label='Validation Accuracy')

# Menambahkan judul, label sumbu, dan legenda
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')

# Menampilkan plot
plt.show()